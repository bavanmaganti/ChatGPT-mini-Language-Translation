{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPM+y/H5jfGj8r4xVykchiG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Gathering Data\n",
        "\n"
      ],
      "metadata": {
        "id": "ypW94HuOq_Ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is the cornerstone of any machine learning project. For our translation model, we'll use the French-English dataset from TensorFlow's official repository. We'll download and extract the data using TensorFlow's utility functions."
      ],
      "metadata": {
        "id": "DDzA7Z6WsX63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Gathering data using TensorFlow's utility function\n",
        "text_file = tf.keras.utils.get_file(\n",
        "    fname='fra-eng.zip',\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\",\n",
        "    extract=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "vvOrRk2ErQ-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing"
      ],
      "metadata": {
        "id": "5nXgmjS-sxig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have the data, the next step is preprocessing. We'll normalize the text, handle special characters, and format it appropriately for training."
      ],
      "metadata": {
        "id": "AQnbr17-s4a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pathlib\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "# Defining the path to the text file\n",
        "text_file = pathlib.Path(text_file).parent / 'fra.txt'\n",
        "\n",
        "def normalize(line):\n",
        "    # Normalize unicode characters, strip leading/trailing whitespace, convert to lowercase\n",
        "    line = unicodedata.normalize(\"NFKC\", line.strip().lower())\n",
        "    # Handle special characters and add start and end tokens for the target language (French)\n",
        "    line = re.sub(r\"^([^ \\w])(?!\\s)\", r\"\\1\", line)\n",
        "    line = re.sub(r\"(\\s[^ \\w])(?!\\s)\", r\"\\1\", line)\n",
        "    line = re.sub(r\"(?!\\s)([^ \\w])$\", r\"\\1\", line)\n",
        "    line = re.sub(r\"(?!\\s)([^ \\w]\\s)\", r\"\\1\", line)\n",
        "    eng, fre = line.split(\"\\t\")\n",
        "    fre = '[start] ' + fre + ' [end]'\n",
        "    return eng, fre\n",
        "\n",
        "# Read and normalize the text pairs\n",
        "with open(text_file) as fp:\n",
        "    text_pairs = [normalize(line) for line in fp]\n",
        "\n"
      ],
      "metadata": {
        "id": "355j57lDs6bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization and Statistics"
      ],
      "metadata": {
        "id": "nVHXScZJtArM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training, it's crucial to tokenize our text data and understand its characteristics, such as the vocabulary size and maximum sequence lengths."
      ],
      "metadata": {
        "id": "fqxKKPRYtEI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Statistics\n",
        "\n",
        "# Initialize sets to store unique tokens for English and French\n",
        "eng_tokens, fre_tokens = set(), set()\n",
        "# Initialize variables to store maximum sequence lengths\n",
        "eng_maxlen, fre_maxlen = 0, 0\n",
        "\n",
        "# Iterate through text pairs to tokenize and compute statistics\n",
        "for eng, fre in text_pairs:\n",
        "    eng_token, fre_token = eng.split(), fre.split()\n",
        "    eng_maxlen = max(eng_maxlen, len(eng_token))\n",
        "    fre_maxlen = max(fre_maxlen, len(fre_token))\n",
        "    eng_tokens.update(eng_token)\n",
        "    fre_tokens.update(fre_token)\n",
        "\n",
        "# Print statistics\n",
        "print(f\"Total tokens in English: {len(eng_tokens)}\")\n",
        "print(f\"Total tokens in French: {len(fre_tokens)}\")\n",
        "print(f\"Maximum length of English sequence: {eng_maxlen}\")\n",
        "print(f\"Maximum length of French sequence: {fre_maxlen}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "752hpM3ZtGLS",
        "outputId": "81c17548-4bbd-4f91-dbec-0b4b3b541cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens in English: 25365\n",
            "Total tokens in French: 42027\n",
            "Maximum length of English sequence: 47\n",
            "Maximum length of French sequence: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Serialization"
      ],
      "metadata": {
        "id": "7e1moW2btLwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we'll serialize our preprocessed data for future use."
      ],
      "metadata": {
        "id": "5oD4-DuWtQGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Serialize preprocessed data for future use\n",
        "with open(\"text_pairs.pickle\", 'wb') as fp:\n",
        "    pickle.dump(text_pairs, fp)\n"
      ],
      "metadata": {
        "id": "m1GGbgL1tSGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding Layer"
      ],
      "metadata": {
        "id": "1tOm_p1wtbAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step in building our model is data transformation. We'll preprocess our text data, vectorize it, and create TensorFlow datasets for training and testing.\n"
      ],
      "metadata": {
        "id": "9Mj1KlGvtp-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "# Load preprocessed text pairs\n",
        "with open(\"text_pairs.pickle\", 'rb') as fp:\n",
        "    text_pairs = pickle.load(fp)\n",
        "\n",
        "# Shuffle the data\n",
        "random.shuffle(text_pairs)\n",
        "\n",
        "# Split into train and test sets\n",
        "n_val = int(0.15 * len(text_pairs))\n",
        "n_train = len(text_pairs) - 2 * n_val\n",
        "train_pair = text_pairs[:n_train]\n",
        "test_pair = text_pairs[n_train: n_train + n_val]\n",
        "\n",
        "# Vocabulary sizes and sequence length\n",
        "vocab_en = 10000\n",
        "vocab_fr = 20000\n",
        "seq_length = 25\n",
        "\n",
        "# Initialize TextVectorization layers\n",
        "eng_vect = TextVectorization(\n",
        "    max_tokens=vocab_en,\n",
        "    standardize=None,\n",
        "    split='whitespace',\n",
        "    output_mode='int',\n",
        "    output_sequence_length=seq_length\n",
        ")\n",
        "\n",
        "fre_vect = TextVectorization(\n",
        "    max_tokens=vocab_fr,\n",
        "    standardize=None,\n",
        "    split='whitespace',\n",
        "    output_mode='int',\n",
        "    output_sequence_length=seq_length + 1  # +1 for start token\n",
        ")\n",
        "\n",
        "# Adapt TextVectorization layers to training data\n",
        "train_eng = [pair[0] for pair in train_pair]\n",
        "train_fre = [pair[1] for pair in train_pair]\n",
        "\n",
        "eng_vect.adapt(train_eng)\n",
        "fre_vect.adapt(train_fre)\n",
        "\n",
        "\n",
        "# Serialize the vectorization layers and training/test data\n",
        "with open('vectorize.pickle', 'wb') as fp:\n",
        "    data = {'train': train_pair,\n",
        "            'test': test_pair,\n",
        "            'eng_vect': eng_vect.get_config(),\n",
        "            'fre_vect': fre_vect.get_config(),\n",
        "            'eng_weights': eng_vect.get_weights(),\n",
        "            'fre_weights': fre_vect.get_weights()\n",
        "            }\n",
        "    pickle.dump(data, fp)\n",
        "\n",
        "# Load serialized data\n",
        "with open(\"vectorize.pickle\", 'rb') as fp:\n",
        "    data = pickle.load(fp)\n",
        "\n",
        "# Retrieve train and test pairs\n",
        "train_pair = data['train']\n",
        "test_pair = data['test']\n",
        "\n",
        "# Reconstruct TextVectorization layers\n",
        "eng_vect = TextVectorization.from_config(data['eng_vect'])\n",
        "eng_vect.set_weights(data['eng_weights'])\n",
        "fre_vect = TextVectorization.from_config(data['fre_vect'])\n",
        "fre_vect.set_weights(data['fre_weights'])\n",
        "\n",
        "# Define function to format dataset\n",
        "def format_dataset(eng, fre):\n",
        "    eng = eng_vect(eng)\n",
        "    fre = fre_vect(fre)\n",
        "    source = {'encode_inp': eng,\n",
        "              'decode_inp': fre[:, :-1]\n",
        "              }\n",
        "    target = fre[:, 1:]\n",
        "    return (source, target)\n",
        "\n",
        "# Define function to create dataset\n",
        "def make_dataset(pairs, batchsize=64):\n",
        "    eng_text, fre_text = zip(*pairs)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(eng_text), list(fre_text)))\n",
        "    return dataset.shuffle(2048).batch(batchsize).map(format_dataset).prefetch(16).cache()\n",
        "\n",
        "# Create TensorFlow datasets for training and testing\n",
        "train_ds = make_dataset(train_pair)\n",
        "test_ds = make_dataset(test_pair)\n"
      ],
      "metadata": {
        "id": "5SDUdYust0VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positional Embedding"
      ],
      "metadata": {
        "id": "9dpABUN-t7wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's implement the positional embedding layer. This layer is essential for helping the model understand the sequential order of tokens in a sentence."
      ],
      "metadata": {
        "id": "ktr2sl5cuB3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to generate positional encoding matrix\n",
        "def pos_enc_matrix(L, d, n=10000):\n",
        "    assert d % 2 == 0\n",
        "    d2 = d // 2\n",
        "\n",
        "    P = np.zeros((L, d))\n",
        "    k = np.arange(L).reshape(-1, 1)\n",
        "    i = np.arange(d2).reshape(1, -1)\n",
        "\n",
        "    denom = np.power(n, -i / d2)\n",
        "    args = k * denom\n",
        "\n",
        "    P[:, ::2] = np.sin(args)\n",
        "    P[:, 1::2] = np.cos(args)\n",
        "    return P\n",
        "\n",
        "# Custom Keras layer for positional embedding\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, seq_length, vocab_size, embed_dim, **kwargs):\n",
        "      super().__init__(**kwargs)\n",
        "      self.seq_length = seq_length\n",
        "      self.vocab_size = vocab_size\n",
        "      self.embed_dim = embed_dim\n",
        "\n",
        "      self.token_embeddings = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
        "      matrix = pos_enc_matrix(seq_length, embed_dim)\n",
        "\n",
        "      self.positional_embedding = tf.constant(matrix, dtype='float32')\n",
        "\n",
        "  def call(self, inputs):\n",
        "      embedded_tokens = self.token_embeddings(inputs)\n",
        "      return embedded_tokens + self.positional_embedding\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "      return self.token_embeddings.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def get_config(self):\n",
        "      config = super().get_config()\n",
        "      config.update({\n",
        "          'seq_length': self.seq_length,\n",
        "          'vocab_size': self.vocab_size,\n",
        "          'embed_dim': self.embed_dim\n",
        "      })\n",
        "\n",
        "# Usage and Validation\n",
        "vocab_en = 10000\n",
        "seq_length = 25\n",
        "\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    embed_en = PositionalEmbedding(seq_length, vocab_en, embed_dim=512)\n",
        "    en_emb = embed_en(inputs['encode_inp'])\n",
        "    print(en_emb._keras_mask)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Hyethu6ZzVPR",
        "outputId": "53b2d484-c579-414f-c438-6e9428d0b678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:55 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::MemoryCacheImpl::Prefetch::Map: Table not initialized.\n\t [[{{node text_vectorization_7_1/None_Lookup/LookupTableFindV2}}]] [Op:IteratorGetNext] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-0b0abda1f5b4>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0membed_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0men_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_en\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encode_inp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5983\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:55 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::MemoryCacheImpl::Prefetch::Map: Table not initialized.\n\t [[{{node text_vectorization_7_1/None_Lookup/LookupTableFindV2}}]] [Op:IteratorGetNext] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JPakgZzn0Zrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Self-Attention Layer\n",
        "The self-attention mechanism allows our model to weigh the importance of different words within the same input sequence. Let's define a function to create a self-attention layer.\n"
      ],
      "metadata": {
        "id": "aPvJMX8M5Id1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def self_attention(input_shape, prefix='att', mask=False, **kwargs):\n",
        "    # Define inputs\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f\"{prefix}_in1\")\n",
        "\n",
        "    # Multi-head attention layer\n",
        "    attention = tf.keras.layers.MultiHeadAttention(name=f\"{prefix}_att1\", **kwargs)\n",
        "    norm = tf.keras.layers.LayerNormalization(name=f'{prefix}_norm1')\n",
        "    add = tf.keras.layers.Add(name=f'{prefix}_add1')\n",
        "\n",
        "    # Apply attention mechanism\n",
        "    attout = attention(query=inputs, value=inputs, key=inputs, use_causal_mask=mask)\n",
        "\n",
        "    # Apply normalization and residual connection\n",
        "    output = norm(add([inputs, attout]))\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=output, name=f\"{prefix}_att\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "G-YlTbXs5UXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross-Attention Layer\n",
        "\n",
        "The cross-attention layer enables our model to focus on relevant information from an external context, such as the source sentence in translation tasks. Let's define a function to create a cross-attention layer."
      ],
      "metadata": {
        "id": "dK8AuVaA5YGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_attention(input_shape, context_shape, prefix='att', **kwargs):\n",
        "    # Define inputs\n",
        "    context = tf.keras.layers.Input(shape=context_shape, dtype='float32', name=f\"{prefix}_ctx2\")\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in2')\n",
        "\n",
        "    # Multi-head attention layer\n",
        "    attention = tf.keras.layers.MultiHeadAttention(name=f'{prefix}_att2', **kwargs)\n",
        "    norm = tf.keras.layers.LayerNormalization(name=f'{prefix}_norm2')\n",
        "    add = tf.keras.layers.Add(name=f'{prefix}_add2')\n",
        "\n",
        "    # Apply attention mechanism\n",
        "    attout = attention(query=inputs, key=context, value=context)\n",
        "\n",
        "    # Apply normalization and residual connection\n",
        "    output = norm(add([attout, inputs]))\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.Model(inputs=[context, inputs], outputs=output, name=f'{prefix}_crs_at')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Ghu6xpVz5bxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feed-Forward Layer\n",
        "\n",
        "The feed-forward layer consists of two dense layers with a ReLU activation function, followed by dropout and layer normalization. Let's define a function to create the feed-forward layer."
      ],
      "metadata": {
        "id": "YLJydU8L5dwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feed_forward(input_shape, model_dim, ff_dim, dropout=.1, prefix='ff'):\n",
        "    # Define inputs\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in3')\n",
        "\n",
        "    # Dense layers\n",
        "    dense1 = tf.keras.layers.Dense(ff_dim, name=f'{prefix}_ff1', activation='relu')\n",
        "    dense2 = tf.keras.layers.Dense(model_dim, name=f'{prefix}_ff2')\n",
        "    drop = tf.keras.layers.Dropout(dropout, name=f'{prefix}_drop')\n",
        "    add = tf.keras.layers.Add(name=f\"{prefix}_add3\")\n",
        "\n",
        "    # Apply feed-forward transformation\n",
        "    ffout = drop(dense2(dense1(inputs)))\n",
        "\n",
        "    # Layer normalization and residual connection\n",
        "    norm = tf.keras.layers.LayerNormalization(name=f'{prefix}_norm3')\n",
        "    output = norm(add([inputs, ffout]))\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=output, name=f'{prefix}_ff')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8wv40NB85j2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder Layer\n",
        "\n",
        "The encoder processes the input sequence and extracts meaningful representations. It consists of self-attention and feed-forward layers."
      ],
      "metadata": {
        "id": "-ZiOuPDd56KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def encoder(input_shape, key_dim, ff_dim, dropout=0.1, prefix='enc', **kwargs):\n",
        "    # Define a Sequential model for the encoder\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in0'), # Input layer\n",
        "        self_attention(input_shape, prefix=prefix, key_dim=key_dim, mask=False, **kwargs), # Self-attention layer\n",
        "        feed_forward(input_shape, key_dim, ff_dim, dropout, prefix) # Feed-forward layer\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "NPyqqy3P5-dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder Layer\n",
        "\n",
        "The decoder takes the encoder's output and generates the translated sequence. It comprises self-attention, cross-attention, and feed-forward layers."
      ],
      "metadata": {
        "id": "Dq6iqNcr6Avz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(input_shape, key_dim, ff_dim, dropout=0.1, prefix='dec', **kwargs):\n",
        "    # Define inputs for decoder\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in0')\n",
        "    context = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_ctx0')\n",
        "\n",
        "    # Self-attention and cross-attention layers\n",
        "    att_model = self_attention(input_shape, key_dim=key_dim, mask=True, prefix=prefix, **kwargs)\n",
        "    cross_model = cross_attention(input_shape, input_shape, key_dim=key_dim, prefix=prefix, **kwargs)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff_model = feed_forward(input_shape, key_dim, ff_dim, dropout, prefix)\n",
        "\n",
        "    # Connect layers\n",
        "    x = att_model(inputs)\n",
        "    x = cross_model([context, x])\n",
        "    output = ff_model(x)\n",
        "\n",
        "    # Define decoder model\n",
        "    model = tf.keras.Model(inputs=[inputs, context], outputs=output, name=prefix)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "BDViDkNz6HMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer Model\n",
        "\n",
        "The transformer model combines the encoder and decoder to perform language translation."
      ],
      "metadata": {
        "id": "Q-WhmUWN6Imi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(num_layers, num_heads, seq_length, key_dim, ff_dim, vocab_size_en, vocab_size_fr, dropout=0.1, name='transformer'):\n",
        "    # Define encoder and decoder inputs\n",
        "    input_enc = tf.keras.layers.Input(shape=(seq_length), dtype='int32', name='encode_inp')\n",
        "    input_dec = tf.keras.layers.Input(shape=(seq_length), dtype='int32', name='decode_inp')\n",
        "\n",
        "    # Positional embeddings for encoder and decoder inputs\n",
        "    emb_enc = PositionalEmbedding(seq_length, vocab_size_en, key_dim, name='embed_enc')\n",
        "    emb_dec = PositionalEmbedding(seq_length, vocab_size_fr, key_dim, name='embed_dec')\n",
        "\n",
        "    # Create encoder and decoder layers\n",
        "    encoders = [encoder(input_shape=(seq_length, key_dim), key_dim=key_dim, ff_dim=ff_dim, dropout=dropout, prefix=f\"enc{i}\", num_heads=num_heads)\n",
        "                for i in range(num_layers)]\n",
        "    decoders = [decoder(input_shape=(seq_length, key_dim), key_dim=key_dim, ff_dim=ff_dim, dropout=dropout, prefix=f\"dec{i}\", num_heads=num_heads)\n",
        "                for i in range(num_layers)]\n",
        "\n",
        "    # Final dense layer\n",
        "    final = tf.keras.layers.Dense(vocab_size_fr, name='linear')\n",
        "\n",
        "    # Apply encoder and decoder layers to inputs\n",
        "    x1 = emb_enc(input_enc)\n",
        "    x2 = emb_dec(input_dec)\n",
        "    for layer in encoders:\n",
        "        x1 = layer(x1)\n",
        "    for layer in decoders:\n",
        "        x2 = layer([x2, x1])\n",
        "\n",
        "    # Generate output\n",
        "    output = final(x2)\n",
        "\n",
        "    try:\n",
        "        del output.keras_mask\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Define transformer model\n",
        "    model = tf.keras.Model(inputs=[input_enc, input_dec], outputs=output, name=name)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "X4mZ48dg6PsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom Learning Rate Schedule\n",
        "A dynamic learning rate schedule can improve training by adjusting the learning rate based on the training progress. Here, we define a custom learning rate schedule that gradually increases the learning rate during the warm-up phase and then decreases it inversely proportional to the square root of the step number."
      ],
      "metadata": {
        "id": "8Uo5ETrJ6dTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, key_dim, warmup_steps=40000):\n",
        "    super().__init__()\n",
        "    self.key_dim = key_dim\n",
        "    self.warmup_steps = warmup_steps\n",
        "    self.d = tf.cast(self.key_dim, tf.float32)\n",
        "\n",
        "  def __call__(self, step):\n",
        "    # Convert step to float32\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    # Calculate learning rate schedule\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    return tf.math.rsqrt(self.d) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "  def get_config(self):\n",
        "    # Configuration for serialization\n",
        "    config ={\n",
        "      \"key_dim\": self.key_dim,\n",
        "      \"warmup_steps\": self.warmup_steps\n",
        "    }\n",
        "    return config\n",
        "\n",
        "# Define key dimension and create learning rate schedule\n",
        "key_dim = 128\n",
        "lr_schedule = CustomSchedule(key_dim)\n"
      ],
      "metadata": {
        "id": "rtskL97w6h0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Masked Loss Function\n",
        "To handle padded sequences during training, we define a masked loss function. This function calculates the loss only for non-padded tokens in the input sequences."
      ],
      "metadata": {
        "id": "m9oRbLuk6kv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  # Create mask for non-padded tokens\n",
        "  mask = label != 0\n",
        "\n",
        "  # Sparse categorical cross-entropy loss\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none'\n",
        "  )\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  # Apply mask to loss\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  # Compute average loss\n",
        "  loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "  return loss\n"
      ],
      "metadata": {
        "id": "X0dLKYcR6nn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Masked Accuracy Metric\n",
        "Similarly, we define a masked accuracy metric to evaluate model performance while considering only non-padded tokens.\n"
      ],
      "metadata": {
        "id": "4987GnmD6p0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_accuracy(label, pred):\n",
        "  # Convert predictions to class labels\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "\n",
        "  # Calculate match between labels and predictions\n",
        "  match = label == pred\n",
        "\n",
        "  # Apply mask to match\n",
        "  mask = label != 0\n",
        "  match = match & mask\n",
        "\n",
        "  # Compute accuracy\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match) / tf.reduce_sum(mask)\n"
      ],
      "metadata": {
        "id": "ZirKwMCT6t2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile and Train the Model\n",
        "Finally, we compile the model using the custom loss function and metrics and train it on the provided datasets."
      ],
      "metadata": {
        "id": "NWEiugdW6vse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with custom loss and metrics\n",
        "model.compile(loss=masked_loss, optimizer=optimizer, metrics=mask_accuracy)\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_ds, epochs=20, validation_data=test_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "xzlRQ5_N6ymL",
        "outputId": "a2d6b822-3ecc-4825-92df-02060e562bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-3aaff857a3f1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compile the model with custom loss and metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing Training History\n",
        "First, let's visualize the training history of our model to understand its performance over epochs."
      ],
      "metadata": {
        "id": "wyjIx7uj65NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizing Training History\n",
        "fig, axs = plt.subplots(2, figsize=(6, 8), sharex=True)\n",
        "fig.suptitle('Training history')\n",
        "x = list(range(1, 21))  # Assuming 20 epochs\n",
        "axs[0].plot(x, history.history[\"loss\"], alpha=0.5, label=\"loss\")\n",
        "axs[0].plot(x, history.history[\"val_loss\"], alpha=0.5, label=\"val_loss\")\n",
        "axs[0].set_ylabel(\"Loss\")\n",
        "axs[0].legend(loc=\"upper right\")\n",
        "axs[1].plot(x, history.history[\"masked_accuracy\"], alpha=0.5, label=\"mask_accuracy\")\n",
        "axs[1].plot(x, history.history[\"val_masked_accuracy\"], alpha=0.5, label=\"val_mask_accuracy\")\n",
        "axs[1].set_ylabel(\"Accuracy\")\n",
        "axs[1].set_xlabel(\"Epoch\")\n",
        "axs[1].legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "20zwOpdm67T8",
        "outputId": "133994a4-7908-48fa-f857-dd5779e722f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-c1892e41dc55>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming 20 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Testing\n",
        "Next, let's define a function to translate English sentences to French using our trained model and evaluate its performance on sample test cases."
      ],
      "metadata": {
        "id": "whSp7z6S6-DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "    # Encode input sentence\n",
        "    enc_tokens = eng_vect([sentence])\n",
        "    lookup = list(fra_vect.get_vocabulary())\n",
        "    start_sent, end_sent = \"[start]\", \"[end]\"\n",
        "    output_sent = [start_sent]\n",
        "    for i in range(seq_length):\n",
        "        # Prepare decoder input\n",
        "        vector = fra_vect([\" \".join(output_sent)])\n",
        "        assert vector.shape == (1, seq_length + 1)\n",
        "        dec_tokens = vector[:, :-1]\n",
        "        assert dec_tokens.shape == (1, seq_length)\n",
        "        # Generate predictions\n",
        "        pred = model([enc_tokens, dec_tokens])\n",
        "        assert pred.shape == (1, seq_len, vocab_size_fr)\n",
        "        # Decode predicted token\n",
        "        word = lookup[np.argmax(pred[0, i, :])]\n",
        "        output_sent.append(word)\n",
        "        if word == end_sent:\n",
        "            break\n",
        "    return output_sent\n",
        "\n",
        "# Test the model on sample test cases\n",
        "test_count = 20\n",
        "for n in range(test_count):\n",
        "    eng_sent, fre_sent = random.choice(test_pairs)\n",
        "    translated = translate(eng_sent)\n",
        "    print(f\"Test case: {n}\")\n",
        "    print(f\"English sentence: {eng_sent}\")\n",
        "    print(f\"Translated sentence: {' '.join(translated)}\")\n",
        "    print(f\"French sentence: {fre_sent}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "9FeC1t-m7CL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}